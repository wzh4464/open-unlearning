# Slurm configuration for single-node GPU cluster
# Strategy: soft constraints + fallback protection (not strict per-job limits)
ClusterName=single
SlurmctldHost=localhost
SlurmUser=root

SlurmctldPort=6817
SlurmdPort=6818

AuthType=auth/munge
CryptoType=crypto/munge

StateSaveLocation=/var/spool/slurmctld
SlurmdSpoolDir=/var/spool/slurmd
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log

# Process tracking (cgroup not supported in Docker, use linuxproc)
# Note: For cgroup support, run outside Docker or use host cgroup namespace
ProctrackType=proctrack/linuxproc
TaskPlugin=task/none

# Resource allocation: CPU/MEM/GPU fine-grained
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory

# Default/max memory per CPU (MB)
# DefMemPerCPU: reasonable default when user doesn't specify --mem
# MaxMemPerCPU: prevent unreasonably large requests
DefMemPerCPU=4000
MaxMemPerCPU=64000

# GPU support
GresTypes=gpu

# Node definition - will be auto-detected/overridden at startup
# RealMemory: leave ~50GB headroom for system (1024GB - 50GB = 974GB)
# Using placeholder values that will be updated by entrypoint script
NodeName=localhost CPUs=16 RealMemory=950000 Gres=gpu:4 State=UNKNOWN

PartitionName=gpu Nodes=localhost Default=YES MaxTime=INFINITE State=UP
