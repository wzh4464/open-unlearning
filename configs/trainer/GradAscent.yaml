defaults:
  - finetune

handler: GradAscent

args:
  # Conservative defaults to prevent catastrophic forgetting
  learning_rate: 1e-6
  num_train_epochs: 3
  lr_scheduler_type: cosine
  warmup_ratio: 0.1
