defaults:
  - finetune

handler: GradDiff

args:
  learning_rate: 5e-6
  num_train_epochs: 5
  lr_scheduler_type: cosine
  warmup_ratio: 0.1

method_args:
  gamma: 1.0
  alpha: 1.0
  retain_loss_type: NLL
