[project]
name = "open-unlearning"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "accelerate>=1.11.0",
    "datasets>=4.3.0",
    "hydra-colorlog>=1.2.0",
    "hydra-core>=1.3.2",
    "hydra-colorlog>=1.2.0",
    "lm-eval>=0.4.9",
    "rouge-score>=0.1.2",
    "scikit-learn>=1.7.2",
    "scipy>=1.16.2",
    "setuptools>=80.9.0",
    "tensorboard>=2.20.0",
    "transformers>=4.57.1",
    "deepspeed>=0.18.4",
    "ninja>=1.13.0",
    "packaging>=25.0",
    "flash-attn>=2.8.3",
]

[project.optional-dependencies]
# Minimal, portable setup for Apple Silicon / Intel macOS using MPS (no CUDA)
macos-mps = [
    "torch>=2.3; platform_system == 'Darwin'",
]

# Fully optimized Linux GPU stack. Install CUDA-enabled torch first (see README/commands),
# then sync this extra with --no-build-isolation so flash-attn can see torch during build.
linux-cuda = [
    "deepspeed>=0.18.1; platform_system == 'Linux'",
    "flash-attn==2.8.3; platform_system == 'Linux'",
]

# Linux CPU-only fallback (no CUDA). Useful on headless CI or dev servers without GPUs.
linux-cpu = [
    "torch>=2.3; platform_system == 'Linux'",
]

# Development tools
dev = [
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]

[tool.uv]
# Build flash-attn without isolation so it can find torch
no-build-isolation-package = ["flash-attn"]

[dependency-groups]
dev = [
    "pytest>=9.0.2",
]

[tool.pytest.ini_options]
pythonpath = ["src"]
