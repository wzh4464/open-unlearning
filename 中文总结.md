# OpenUnlearning 仓库中文总结（含逻辑结构）

本文件从“逻辑结构与数据流”的角度，总结仓库的目录组织、核心模块职责、配置体系以及训练/评估工作流，便于快速理解与扩展。

## 仓库目标

OpenUnlearning 是一个统一的大语言模型遗忘学习（LLM Unlearning）研究框架，提供：
- 基准测试：TOFU、MUSE、WMDP 等
- 方法实现：GradAscent、GradDiff、DPO、NPO、SimNPO、RMU、UNDIAL、WGA、CEU、SatImp、PDU、TIMParameterRollback 等
- 评估指标：概率/ROUGE、隐私泄露、记忆提取、成员推断（MIA）等
- 模型支持：Llama-3.x、Llama-2、Phi-3.5、Gemma、Zephyr 等

## 顶层入口与整体数据流

- 训练/遗忘入口：`src/train.py:1`
  - 读取 Hydra 配置（`configs/train.yaml` 或 `configs/unlearn.yaml`）
  - 加载模型与分词器：`model.get_model()`（`src/model/__init__.py:31`）
  - 构建数据与拼接器：`data.get_data()`、`data.get_collators()`（`src/data/__init__.py:1`）
  - 构建评估器：`evals.get_evaluators()`（`src/evals/__init__.py:1`）
  - 实例化训练器：`trainer.load_trainer()`（`src/trainer/__init__.py:1`）并执行 `train()/evaluate()`

- 评估入口：`src/eval.py:1`
  - 同样经 Hydra 读取 `configs/eval.yaml`
  - 加载模型后，构建评估器集合并逐一 `evaluator.evaluate()`（产出明细与汇总 JSON）

输出目录：`saves/${mode}/${task_name}`（`configs/paths/default.yaml:16`）

## 配置体系（Hydra）

- 核心入口配置：
  - `configs/train.yaml`：标准微调/训练默认（含 `defaults` 链）
  - `configs/unlearn.yaml`：遗忘训练默认（设置 `mode=unlearn`，锚定 `ForgetRetainDataset`）
  - `configs/eval.yaml`：评估默认（设置 `mode=eval` 与 `seed`）
- 分层与覆盖：
  - 模型：`configs/model/*.yaml`（含 `template_args` 与 dtype/FA2 设置）
  - 数据：`configs/data/*.yaml` + `configs/data/datasets/*.yaml`（定义 forget/retain/holdout 等切分）
  - 训练器：`configs/trainer/*.yaml`（注册与方法参数、HF TrainingArguments）
  - 评估：`configs/eval/*.yaml`（TOFU/MUSE/LMEval 的指标集合与参数）
  - 预设实验：`configs/experiment/**`（不同基准/方法/模型组合的推荐配置）
  - 路径与 Hydra 行为：`configs/paths/default.yaml`、`configs/hydra/*.yaml`

命令行可用点记法覆盖任意配置键（Hydra 规则）。

## 模型层（src/model）

- `src/model/__init__.py:1`
  - 注册表：`MODEL_REGISTRY`，默认支持 `AutoModelForCausalLM` 与 `ProbedLlamaForCausalLM`
  - `get_model(cfg)`：解析 `model_args/tokenizer_args`，处理 `torch_dtype` 与 `flash_attention_2` 约束（`get_dtype`）并加载分词器（自动补齐 `eos/pad`）

## 数据层（src/data）

- 入口与注册：`src/data/__init__.py:1`
  - `DATASET_REGISTRY`、`COLLATOR_REGISTRY`，通过 handler 名称动态构建
  - `get_data(data_cfg, mode)`：按 split 构建数据集；当 `mode=unlearn` 则将 forget/retain 组合为 `ForgetRetainDataset`
  - `get_collators(...)`：返回单个或字典形式的 collator
- 数据集实现：
  - `QADataset`、`QAwithIdkDataset`、`QAwithAlternateDataset`（`src/data/qa.py`）
  - `ForgetRetainDataset`（`src/data/unlearn.py`）：按 anchor 规则采样 forget/retain 配对样本
  - 预训练/补全：`PretrainingDataset`、`CompletionDataset`（`src/data/pretraining.py`）
- 处理函数：`src/data/utils.py`
  - `preprocess_chat_instance`：模板化对话打包与 label 掩码（-100）
  - `preprocess_pretraining_instance`、`add_dataset_index` 等
- 拼接器：`DataCollatorForSupervisedDataset`（`src/data/collators.py`）支持左右填充、labels 对齐、索引携带

## 训练器层（src/trainer）

- 统一入口与注册：`src/trainer/__init__.py:1`
  - `TRAINER_REGISTRY` 按 `trainer_cfg.handler` 选择类；`load_trainer_args` 将 Hydra 配置转为 `TrainingArguments` 并推导 warmup 步数
  - 注册了 HF `Trainer`、`FinetuneTrainer` 以及各类 Unlearning Trainer
- 基类：
  - `FinetuneTrainer`（`src/trainer/base.py`）覆写 `evaluate`：如单进程时在 `checkpoint-*/evals` 目录运行自定义评估器并记录 JSON
  - `UnlearnTrainer`（`src/trainer/unlearn/base.py`）
    - 对 DeepSpeed 进行引用模型准备（ZeRO3 时 shard 引用模型）
    - 覆写 `prediction_step`：评估集用“父类 compute_loss”，避免方法定制的训练 loss 影响评估
- 方法家族（均覆写 `compute_loss`，核心是“遗忘项 + 保留项”）：
  - `GradAscent`（`grad_ascent.py`）：仅对 forget 做 `-loss`
  - `GradDiff`（`grad_diff.py`）：`gamma * (-forget_loss) + alpha * retain_loss`；retain 可选 `NLL/KL`，`KL` 需引用模型
  - `DPO`/`NPO`（`dpo.py`/`npo.py`）：基于参考模型的偏好损失（`compute_dpo_loss`）
  - `SimNPO`：NPO 的简化近似（对归一化 NLL 应用 `logsigmoid`）
  - `WGA`：对难例加权的“反学习”损失（`compute_wga_loss`）
  - `CEU`：Cross-Entropy Unlearning，将真标签位置的目标概率压至 0（`ceu.py`）
  - `UNDIAL`：基于软标签的对齐-去对齐（`compute_undial_loss`）
  - `SatImp`：满意度×重要度的双权重方案（两个 beta）
  - `RMU`：表示工程式方法，正则限定可训练参数子集，使用嵌入差异/控制向量（`rmu.py`）
  - `PDU`：原始-对偶（primal-dual）优化，对 retain 约束引入对偶参数并按步/轮更新（`pdu.py`）
  - `TIMParameterRollback`：基于训练轨迹的参数回退，在 `train()` 前读取并反向应用 forget 样本的参数更新（`tim_rollback.py`）

## 评估层（src/evals）

- 统一入口与注册：`src/evals/__init__.py:1`
  - `get_evaluators` 根据配置构造多个评估器：`TOFUEvaluator`、`MUSEEvaluator`、`LMEvalEvaluator`
- 评估基类：`Evaluator`（`src/evals/base.py`）
  - 管理 metrics 注册与执行、缓存/覆盖策略、结果落盘：
    - 明细：`${output_dir}/${NAME}_EVAL.json`
    - 汇总：`${output_dir}/${NAME}_SUMMARY.json`
- `LMEvalEvaluator`（`src/evals/lm_eval.py`）
  - 适配 `lm-evaluation-harness`，支持单任务与分组任务（如 `mmlu`）的结果汇总

### 指标体系（src/evals/metrics）

- 注册与装饰器：`METRICS_REGISTRY` + `unlearning_metric`（`src/evals/metrics/__init__.py`、`base.py`）
- 记忆/效用等：`probability`、`rouge`、`truth_ratio`、`extraction_strength`、`exact_memorization`、`hm_aggregate` 等
- 隐私与差异：`privleak`、`rel_diff` 等
- 成员推断（MIA，`src/evals/metrics/mia/`）：`loss`、`min_k`、`min_k++`、`gradnorm`、`zlib`、`reference`，统一通过 `mia_auc` 计算 AUC/ACC
- 工具：`src/evals/metrics/utils.py` 提供概率评估、文本抽取与通用聚合逻辑

## 典型工作流摘要

1) 遗忘训练（unlearn）
- 选择实验预设：如 `configs/experiment/unlearn/tofu/default.yaml`
- 覆盖关键项：`forget_split`、`retain_split`、`trainer` 与 `task_name`
- 执行：`python src/train.py --config-name=unlearn.yaml experiment=unlearn/tofu/default task_name=...`
- 产物：`saves/unlearn/${task_name}/checkpoint-*/` 与（如启用）`checkpoint-*/evals/`

2) 评估（eval）
- 选择评估预设：如 `configs/experiment/eval/tofu/default.yaml`
- 指定模型与参考日志（TOFU 指标需 retain 日志）：`retain_logs_path`
- 执行：`python src/eval.py --config-name=eval.yaml experiment=eval/tofu/default task_name=...`
- 产物：`saves/eval/${task_name}/TOFU_EVAL.json` 与 `TOFU_SUMMARY.json`

## 扩展指南（最小改动路径）

- 新增模型：在 `src/model/__init__.py` 注册类并在 `configs/model/*.yaml` 提供参数模板
- 新增数据/拼接器：在 `src/data/__init__.py` 注册数据类/拼接器，并在 `configs/data/datasets` 下给出数据源描述
- 新增训练方法：在 `src/trainer/unlearn/` 实现并在 `src/trainer/__init__.py` 注册，同时提供 `configs/trainer/<Method>.yaml`
- 新增评估器/指标：在 `src/evals/__init__.py`/`src/evals/metrics/__init__.py` 注册，并在 `configs/eval/**` 组织指标组合

## 目录速览（与职责）

- 代码主干：`src/{train.py, eval.py, data/, model/, trainer/, evals/}`
- 配置：`configs/{train.yaml, unlearn.yaml, eval.yaml, model/, data/, trainer/, eval/, experiment/, paths/, hydra/}`
- 文档：`docs/{components.md, experiments.md, evaluation.md, hydra.md, repro.md, links.md}`
- 社区：`community/{benchmarks/, methods/, leaderboard.md}`（方法/基准的模板与脚本）
- 资产：`assets/{banner.png, logo.png}`

---

## 快速使用摘要

环境准备：
```bash
pip install .[lm_eval]
pip install .[dev]
python setup_data.py --eval
```

遗忘训练示例（TOFU + GradAscent）：
```bash
python src/train.py --config-name=unlearn.yaml \
  experiment=unlearn/tofu/default \
  forget_split=forget10 retain_split=retain90 \
  trainer=GradAscent task_name=SAMPLE_UNLEARN
```

评估示例（TOFU）：
```bash
python src/eval.py --config-name=eval.yaml \
  experiment=eval/tofu/default \
  model=Llama-3.2-1B-Instruct \
  task_name=SAMPLE_EVAL
```

---

附：原有项目概述与命令指南（保留）

### 项目概述

OpenUnlearning 是一个统一的大语言模型遗忘学习（LLM Unlearning）研究框架，支持多个基准测试（TOFU、MUSE、WMDP）、12+种遗忘方法、10+种评估指标和7+种模型架构。该框架使用 Hydra 进行配置管理，支持单GPU和分布式训练。

### 主要开发命令

环境设置、代码质量检查、训练与评估的命令示例见上文“快速使用摘要”。
